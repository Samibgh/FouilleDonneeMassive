{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a638260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "import dask.dataframe as dd\n",
    "import fastparquet\n",
    "from sklearn.svm import OneClassSVM\n",
    "try:\n",
    "    os.chdir(\"C:/Users/Sam/Documents/SISE/Fouille de données\")\n",
    "except:\n",
    "    os.chdir(\"/Users/titouanhoude/Documents/GitHub\")\n",
    "    \n",
    "train = pd.read_parquet('train.parquet.gzip')\n",
    "test = pd.read_parquet('test.parquet.gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5cabae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = train.drop([\"FlagImpaye\", \"ZIBZIN\", \"Date\", \"Heure_split\", \"DateTransaction\", \"CodeDecision\", \"Unnamed: 0\"], axis = 1)\n",
    "\n",
    "Ytrain = pd.DataFrame(train.FlagImpaye)\n",
    "Ytrain = train['FlagImpaye'].astype('int')\n",
    "\n",
    "Xtest  = test.drop([\"FlagImpaye\",\"ZIBZIN\", \"Date\", \"Heure_split\", \"DateTransaction\",\"CodeDecision\", 'Unnamed: 0'], axis = 1)\n",
    "Ytest  = test.FlagImpaye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "591a6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_100k = Xtrain.sample(n = 100000)\n",
    "ytrain_100k = Ytrain.sample(n = 100000)\n",
    "test_100k = Ytest.sample(n = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c2083f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13182421 0.11123957 0.001532   0.00289059 0.00617631 0.10361692\n",
      " 0.01879611 0.10973804 0.00353393 0.12014229 0.10318104 0.01071282\n",
      " 0.00229775 0.00833905 0.00228678 0.00191048 0.11139518 0.0143003\n",
      " 0.13608664]\n",
      "(100000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:402: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf = clf.fit(train_100k, ytrain_100k)\n",
    "print(clf.feature_importances_)\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(train_100k)\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "59539fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "\n",
    "nbFoldValid = 5 # nombre de groupes pour la K-CV\n",
    "\n",
    "models2={'SVC': SVC(),\n",
    "       'RandomForest': RandomForestClassifier(random_state=0),\n",
    "       'XGBRFClassifier' : XGBRFClassifier(random_state=0),\n",
    "       'GradientBoosting' : GradientBoostingClassifier(random_state=0),\n",
    "        'GradientBoosting' : GradientBoostingClassifier(random_state=0)\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e00dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application des algorithmes \n",
    "\n",
    "def applyAlgo(algo,Xtrain, ytrain, Xtest, ytest):\n",
    "\n",
    "    # On commence par indiquer ce que l'on va faire avec chaque algorithme.\n",
    "    # on prendra soin de préciser les hyper-paramètres dont dépend l'algorithme\n",
    "\n",
    "    if algo == \"SVC\":\n",
    "        clf = SVC()\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        rankTrain = clf.predict(Xtrain)\n",
    "        rankTest = clf.predict(Xtest)\n",
    "\n",
    "    elif algo == \"RandomForest\":\n",
    "        clf = RandomForestClassifier(random_state=0)\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        rankTest = clf.predict(Xtest)\n",
    "\n",
    "    elif algo == \"GradientBoostingClassifier\":\n",
    "        clf = GradientBoostingClassifier(random_state=0)\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        rankTest = clf.predict(Xtest)\n",
    "        \n",
    "    elif algo == \"AdaBoostClassifier\":\n",
    "        clf = AdaBoostClassifier(random_state=0)\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        rankTest = clf.predict(Xtest)\n",
    "        \n",
    "    elif algo == \"XGBRFClassifier\":\n",
    "        clf = XGBRFClassifier(random_state=0)\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        rankTest = clf.predict(Xtest)\n",
    "\n",
    "   # Cette deuxième partie permet d'indiquer quelle est la mesure de performance que \n",
    "   # vous souhaitez considérer pour votre étude en cours\n",
    "        ctest = confusion_matrix(ytest, rankTest)\n",
    "        ftest = round(2*ctest[1,1]/(2*ctest[1,1]+ctest[0,1]+ctest[1,0]),4)\n",
    "\n",
    "    return (ftest*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1ececb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe_Sampling = Pipeline([('Smote', BorderlineSMOTE()), ('Modele',model)])\n",
    "pipe_Sampling = Pipeline([('Smote', BorderlineSMOTE()), ('Modele',model)])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import average_precision_score, confusion_matrix\n",
    "#from functions import loadCsv, oneHotEncodeColumns, data_recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fab815",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['RandomForest', 'XGBRFClassifier' , 'GradientBoosting', 'GradientBoosting']# 'SVC']\n",
    "\n",
    "import time\n",
    "Fmesure = []\n",
    "execution = []\n",
    "\n",
    "# Normalisation\n",
    "normalizer = Normalizer()\n",
    "normalizer.fit(Xtrain)\n",
    "Xtrain = normalizer.transform(Xtrain)\n",
    "Xtest = normalizer.transform(Xtest)\n",
    "\n",
    "for i in models : \n",
    "    start = time.time()\n",
    "    # Fin normalisation\n",
    "    apTest = applyAlgo(models, Xtrain, Ytrain, Xtest, Ytest)\n",
    "    Fmesure.append(apTest) \n",
    "    end = time.time()\n",
    "    elapsed = end - start \n",
    "    execution.append(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cf8c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "333d2c9757a75282c9d4867cccb346dd97fbdd6438562bec117fa31e687fe23c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
