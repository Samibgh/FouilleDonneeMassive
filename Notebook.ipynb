{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/46/7rlt2f9x4szchbk_4z7ycdtc0000gn/T/ipykernel_4910/448400790.py:21: DtypeWarning: Columns (1,2,5,6,7,8,9,15,16,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"guillaume.txt\", sep = \";\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4646774 entries, 0 to 4646773\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Dtype \n",
      "---  ------                    ----- \n",
      " 0   ZIBZIN                    object\n",
      " 1   IDAvisAutorisationCheque  object\n",
      " 2   FlagImpaye                object\n",
      " 3   Montant                   object\n",
      " 4   DateTransaction           object\n",
      " 5   CodeDecision              object\n",
      " 6   VerifianceCPT1            object\n",
      " 7   VerifianceCPT2            object\n",
      " 8   VerifianceCPT3            object\n",
      " 9   D2CB                      object\n",
      " 10  ScoringFP1                object\n",
      " 11  ScoringFP2                object\n",
      " 12  ScoringFP3                object\n",
      " 13  TauxImpNb_RB              object\n",
      " 14  TauxImpNB_CPM             object\n",
      " 15  EcartNumCheq              object\n",
      " 16  NbrMagasin3J              object\n",
      " 17  DiffDateTr1               object\n",
      " 18  DiffDateTr2               object\n",
      " 19  DiffDateTr3               object\n",
      " 20  CA3TRetMtt                object\n",
      " 21  CA3TR                     object\n",
      " 22  Heure                     object\n",
      "dtypes: object(23)\n",
      "memory usage: 815.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ZIBZIN                      0\n",
       "IDAvisAutorisationCheque    0\n",
       "FlagImpaye                  0\n",
       "Montant                     0\n",
       "DateTransaction             0\n",
       "CodeDecision                0\n",
       "VerifianceCPT1              0\n",
       "VerifianceCPT2              0\n",
       "VerifianceCPT3              0\n",
       "D2CB                        0\n",
       "ScoringFP1                  0\n",
       "ScoringFP2                  0\n",
       "ScoringFP3                  0\n",
       "TauxImpNb_RB                0\n",
       "TauxImpNB_CPM               0\n",
       "EcartNumCheq                0\n",
       "NbrMagasin3J                0\n",
       "DiffDateTr1                 0\n",
       "DiffDateTr2                 0\n",
       "DiffDateTr3                 0\n",
       "CA3TRetMtt                  0\n",
       "CA3TR                       0\n",
       "Heure                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "import dask.dataframe as dd\n",
    "\n",
    "try:\n",
    "    os.chdir(\"C:/Users/Sam/Documents/SISE/Fouille de données\")\n",
    "except:\n",
    "    os.chdir(\"/Users/titouanhoude/Documents/GitHub\")\n",
    "\n",
    "data = pd.read_csv(\"guillaume.txt\", sep = \";\")\n",
    "data.info()\n",
    "\n",
    "data.head()\n",
    "\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode type of variable \n",
    "var_quanti = [\"Montant\",\"VerifianceCPT1\", \"VerifianceCPT2\", \"VerifianceCPT3\",\"D2CB\",\"ScoringFP1\",\"ScoringFP2\",\"ScoringFP3\",\"TauxImpNb_RB\",\"TauxImpNB_CPM\",\"EcartNumCheq\",\"NbrMagasin3J\",\"DiffDateTr1\", \"DiffDateTr2\",\"DiffDateTr3\",\"CA3TRetMtt\",\"CA3TR\",\"Heure\"]\n",
    "\n",
    "var_quali = [\"FlagImpaye\" , \"IDAvisAutorisationCheque\" , \"CodeDecision\"]\n",
    "\n",
    "# split variable to have date and hour\n",
    "data[['Date','Heure_split']] = data['DateTransaction'].astype(str).str.split(\" \" , expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m var_quanti :\n\u001b[0;32m----> 3\u001b[0m     data[i] \u001b[39m=\u001b[39m data[i]\u001b[39m.\u001b[39;49mapply(pd\u001b[39m.\u001b[39;49mto_numeric, downcast \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mfloat\u001b[39;49m\u001b[39m\"\u001b[39;49m, errors \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mcoerce\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m     data[i] \u001b[39m=\u001b[39m data[i]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, regex\u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\u001b[39m.\u001b[39mround(\u001b[39m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m var_quali :\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1157\u001b[0m             values,\n\u001b[1;32m   1158\u001b[0m             f,\n\u001b[1;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:139\u001b[0m, in \u001b[0;36mApply.__init__.<locals>.f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x):\n\u001b[0;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m func(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in var_quanti :\n",
    "\n",
    "    #data[i] = data[i].apply(pd.to_numeric, downcast = \"float\", errors = \"coerce\")\n",
    "    data[i] = data[i].replace(\",\", \".\", regex= True).astype(float).round(0)\n",
    "\n",
    "for i in var_quali :\n",
    "    \n",
    "    data[i] = data[i].astype(object)\n",
    "    \n",
    "\n",
    "#look the number modality \n",
    "data.FlagImpaye.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data[\u001b[39m'\u001b[39;49m\u001b[39mDate\u001b[39;49m\u001b[39m'\u001b[39;49m] : \n\u001b[1;32m      5\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m2017-09-01\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m      6\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for i in data['Date'] : \n",
    "    \n",
    "    \n",
    "    if i ==\"2017-09-01\":\n",
    "        break\n",
    "    else:\n",
    "        index += 1\n",
    "        train = data.iloc[:index, :]\n",
    "\n",
    "\n",
    "test = data.iloc[index:, :]\n",
    "\n",
    "\n",
    "train.to_csv(\"C:/Users/Sam/Documents/GitHub/FouilleDonneeMassive/train.csv\")\n",
    "test.to_csv(\"C:/Users/Sam/Documents/GitHub/FouilleDonneeMassive/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\"\"\"\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in range(train.shape[1]):\n",
    "    train.loc[:,i] = le.fit_transform(train.loc[:,i])\n",
    "    \n",
    "    test.loc[:,i] = le.fit_transform(test.loc[:,i])\n",
    "\"\"\"\n",
    "\n",
    "Xtrain = train.drop([\"FlagImpaye\", \"ZIBZIN\", \"Date\", \"Heure_split\", \"DateTransaction\"], axis = 1)\n",
    "\n",
    "Ytrain = pd.DataFrame(train.FlagImpaye)\n",
    "Ytrain = Ytrain['FlagImpaye'].astype('int')\n",
    "\n",
    "Xtest  = test.drop([\"FlagImpaye\",\"ZIBZIN\", \"Date\", \"Heure_split\", \"DateTransaction\"], axis = 1)\n",
    "Ytest  = test.FlagImpaye\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "\"\"\"\n",
    "sm = BorderlineSMOTE(random_state = 0)\n",
    "#XBdSmote , YBdSmote = sm.fit_resample(Xtrain, Ytrain)\n",
    "\n",
    "def echant(ech, X, Y):\n",
    "    \n",
    "    XBdSmote , YBdSmote = ech.fit_resample(X, Y)\n",
    "    \n",
    "    return XBdSmote , YBdSmote\n",
    "\n",
    "\n",
    "result = Parallel(n_jobs=2)(delayed(echant)(sm,Xtrain, Ytrain) for i in range(1))\n",
    "\"\"\"\n",
    "\n",
    "names=[]\n",
    "f1score_ =[]\n",
    "\n",
    "models={'SVC': SVC(),\n",
    "       'RandomForest': RandomForestClassifier(),\n",
    "       'DecisionTree': DecisionTreeClassifier(),\n",
    "       'Naïve Bayes': GaussianNB(), \n",
    "       'Neural Network': MLPClassifier(),\n",
    "       'knn' : KNeighborsClassifier(),\n",
    "       'LDA': LinearDiscriminantAnalysis(),\n",
    "       'GradientBoosting' : GradientBoostingClassifier(), \n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend('multiprocessing', n_jobs=5) as parallel:\n",
    "    \n",
    "    sm = BorderlineSMOTE(random_state = 0)\n",
    "    XBdSmote , YBdSmote = sm.fit_resample(Xtrain, Ytrain)\n",
    "\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        name_model = model\n",
    "        name_fit = name_model.fit(XBdSmote , YBdSmote)\n",
    "        name_pred = name_fit.predict(Xtest)\n",
    "        f1score = f1_score(Ytest,name_pred, average = \"macro\")\n",
    "        names.append(name)\n",
    "        f1score_.append(f1score)\n",
    "        \n",
    "score_df = pd.DataFrame(zip(names, f1score_))\n",
    "score_df.columns = [\"Nom\", \"Score\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def train_model(X, y,Xtest, name, model):\n",
    "        \n",
    "    name_model = model\n",
    "    name_fit = name_model.fit(X,y)\n",
    "    name_pred = name_fit.predict(Xtest)\n",
    "    f1score = f1_score(Ytest,name_pred, average = \"macro\")\n",
    "    names.append(name)\n",
    "    f1score_.append(f1score)\n",
    "    \n",
    "    return names, f1score_\n",
    "\n",
    "                               \n",
    "Model = Parallel(n_jobs=8)(delayed(train_model)(result[0], result[1],Xtest,name, model) for name, model in models.items())\n",
    "\n",
    "\n",
    "score_df = pd.DataFrame(zip(Model[0], Model[1]))\n",
    "score_df.columns = [\"Nom\", \"Score\"]\n",
    "\"\"\"\n",
    "score_df.to_csv(\"res.csv\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for name, model in models.items():\n",
    "    name_model = model\n",
    "    name_fit = name_model.fit(XBdSmote,YBdSmote)\n",
    "    name_pred = name_fit.predict(Xtest)\n",
    "    f1score = f1_score(Ytest,name_pred, average = \"macro\")\n",
    "    names.append(name)\n",
    "    f1score_.append(f1score)\n",
    "\n",
    "score_df = pd.DataFrame(zip(names, f1score_))\n",
    "score_df.columns = [\"Nom\", \"Score\"]\n",
    "\n",
    "try: \n",
    "    score_df.to_csv('/Users/titouanhoude/Documents/GitHub/FouilleDonneeMassive/res.csv', index = False, sep=';', encoding='utf-8')\n",
    "except:\n",
    "    score_df.to_csv('C:/Users/Sam/Documents/GitHub/FouilleDonneeMassive/res.csv', index = False, sep=';', encoding='utf-8')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
