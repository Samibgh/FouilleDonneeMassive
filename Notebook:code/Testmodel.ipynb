{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be234ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "import dask.dataframe as dd\n",
    "import fastparquet\n",
    "from sklearn.svm import OneClassSVM\n",
    "try:\n",
    "    os.chdir(\"C:/Users/Sam/Documents/SISE/Fouille de donnÃ©es\")\n",
    "except:\n",
    "    os.chdir(\"/Users/titouanhoude/Documents/GitHub\")\n",
    "    \n",
    "train = pd.read_parquet('train.parquet.gzip')\n",
    "test = pd.read_parquet('test.parquet.gzip')\n",
    "train_test = train.sample(n = 100000)\n",
    "test_test = test.sample(n = 100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf19a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99382\n",
       "1      618\n",
       "Name: FlagImpaye, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test[\"FlagImpaye\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c5317c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = train_test.drop([\"FlagImpaye\", \"ZIBZIN\", \"Date\", \"Heure_split\", \"DateTransaction\", \"Unnamed: 0\"], axis = 1)\n",
    "\n",
    "Ytrain = pd.DataFrame(train_test.FlagImpaye)\n",
    "Ytrain = train_test['FlagImpaye'].astype('int')\n",
    "\n",
    "Xtest  = test_test.drop([\"FlagImpaye\",\"ZIBZIN\", \"Date\", \"Heure_split\", \"DateTransaction\", 'Unnamed: 0'], axis = 1)\n",
    "Ytest  = test_test.FlagImpaye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea6b88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ee2997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(Ytrain)\n",
    "cw = class_weight.compute_class_weight(class_weight = 'balanced',classes =  np.unique(Ytrain),y= Ytrain)\n",
    "weights = dict(zip(classes,cw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2b2d839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:53:33] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "model = XGBRFClassifier(class_weight=weights)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "y_score = model.predict_proba(Xtest)\n",
    "y_pred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4972ebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99072\n",
      "           1       0.98      0.66      0.79       928\n",
      "\n",
      "    accuracy                           1.00    100000\n",
      "   macro avg       0.99      0.83      0.89    100000\n",
      "weighted avg       1.00      1.00      1.00    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "tab = classification_report(Ytest, y_pred)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49f840d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    99391\n",
      "1      609\n",
      "Name: FlagImpaye, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def sampling_strategy(X,y,n_samples, t='majority'):\n",
    "    target_classes = ''\n",
    "    if t == 'majority':\n",
    "        target_classes = y.value_counts() > n_samples\n",
    "    elif t == 'minority':\n",
    "        target_classes = y.value_counts() < n_samples\n",
    "    tc = target_classes[target_classes == True].index\n",
    "    #target_classes_all = y.value_counts().index\n",
    "    sampling_strategy = {}\n",
    "    for target in tc:\n",
    "        sampling_strategy[target] = n_samples\n",
    "    return sampling_strategy\n",
    "\n",
    "count = train_test.FlagImpaye.value_counts()\n",
    "print(count)\n",
    "n_samples = int(count.median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eab2986e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The 'sampling_strategy' parameter of OneSidedSelection must be a float in the range (0, 1], a str among {'auto', 'majority', 'not majority', 'not minority', 'all'}, an instance of 'list' or a callable. Got {0: 50000} instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46868\\1899151995.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneSidedSelection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0munder_sampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneSidedSelection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'majority'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_under\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_under\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munder_sampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \"\"\"\n\u001b[1;32m--> 202\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m_validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_parameter_constraints\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             validate_parameter_constraints(\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     96\u001b[0m                     )\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m     99\u001b[0m                     \u001b[1;34mf\"The {param_name!r} parameter of {caller_name} must be\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                     \u001b[1;34mf\" {constraints_str}. Got {param_val!r} instead.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The 'sampling_strategy' parameter of OneSidedSelection must be a float in the range (0, 1], a str among {'auto', 'majority', 'not majority', 'not minority', 'all'}, an instance of 'list' or a callable. Got {0: 50000} instead."
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "under_sampler = OneSidedSelection(sampling_strategy=sampling_strategy(Xtrain, Ytrain,n_samples,t='majority'))\n",
    "X_under, y_under = under_sampler.fit_resample(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e78b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "over_sampler = SMOTE(sampling_strategy=sampling_strategy(Xtrain, Ytrain,n_samples, t='minority'),k_neighbors=3)\n",
    "X_bal, y_bal = over_sampler.fit_resample(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "733006c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:24:53] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = XGBRFClassifier(class_weight=weights)\n",
    "model.fit(X_bal, y_bal )\n",
    "y_score = model.predict_proba(Xtest)\n",
    "y_pred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e809c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99072\n",
      "           1       0.57      0.69      0.62       928\n",
      "\n",
      "    accuracy                           0.99    100000\n",
      "   macro avg       0.78      0.84      0.81    100000\n",
      "weighted avg       0.99      0.99      0.99    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "tab = classification_report(Ytest, y_pred)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4a3dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "y_score = model.predict_proba(Xtest)\n",
    "y_pred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7292825d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99072\n",
      "           1       0.90      0.65      0.76       928\n",
      "\n",
      "    accuracy                           1.00    100000\n",
      "   macro avg       0.95      0.83      0.88    100000\n",
      "weighted avg       1.00      1.00      1.00    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "tab = classification_report(Ytest, y_pred)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2e9ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = train.sample(n = 100000, weights=train['FlagImpaye'].map(weights))\n",
    "test_test = test.sample(n = 100000,weights=test['FlagImpaye'].map(weights))\n",
    "\n",
    "Xtrain = train_test.drop([\"FlagImpaye\", \"ZIBZIN\", \"Date\", \"Heure_split\", \"DateTransaction\", \"Unnamed: 0\"], axis = 1)\n",
    "\n",
    "Ytrain = pd.DataFrame(train_test.FlagImpaye)\n",
    "Ytrain = train_test['FlagImpaye'].astype('int')\n",
    "\n",
    "Xtest  = test_test.drop([\"FlagImpaye\",\"ZIBZIN\", \"Date\", \"Heure_split\", \"DateTransaction\", 'Unnamed: 0'], axis = 1)\n",
    "Ytest  = test_test.FlagImpaye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3cd44bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     93427\n",
      "           1       0.98      0.69      0.81      6573\n",
      "\n",
      "    accuracy                           0.98    100000\n",
      "   macro avg       0.98      0.85      0.90    100000\n",
      "weighted avg       0.98      0.98      0.98    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "model = RandomForestClassifier(\n",
    "                        class_weight =weights)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "y_score = model.predict_proba(Xtest)\n",
    "y_pred = model.predict(Xtest)\n",
    "from sklearn.metrics import classification_report\n",
    "tab = classification_report(Ytest, y_pred)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ddb26e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     93427\n",
      "           1       0.99      0.69      0.81      6573\n",
      "\n",
      "    accuracy                           0.98    100000\n",
      "   macro avg       0.98      0.84      0.90    100000\n",
      "weighted avg       0.98      0.98      0.98    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging_clf = BaggingClassifier(base_estimator=model,\n",
    "                                random_state=0)\n",
    "bagging_clf.fit(Xtrain, Ytrain)\n",
    "y_score = bagging_clf.predict_proba(Xtest)\n",
    "y_pred = bagging_clf.predict(Xtest)\n",
    "from sklearn.metrics import classification_report\n",
    "tab = classification_report(Ytest, y_pred)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b1470183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     93427\n",
      "           1       0.95      0.70      0.81      6573\n",
      "\n",
      "    accuracy                           0.98    100000\n",
      "   macro avg       0.97      0.85      0.90    100000\n",
      "weighted avg       0.98      0.98      0.98    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBRFClassifier()\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging_clf = BaggingClassifier(base_estimator=model,\n",
    "                                random_state=0)\n",
    "bagging_clf.fit(Xtrain, Ytrain)\n",
    "y_score = bagging_clf.predict_proba(Xtest)\n",
    "y_pred = bagging_clf.predict(Xtest)\n",
    "from sklearn.metrics import classification_report\n",
    "tab = classification_report(Ytest, y_pred)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd9923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(class_weight =weights)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "y_score = model.predict_proba(Xtest)\n",
    "y_pred = model.predict(Xtest)\n",
    "from sklearn.metrics import classification_report\n",
    "tab = classification_report(Ytest, y_pred)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "87f9e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "classifier = XGBRFClassifier(max_depth=6,gamma = 1, learning_rate =  0.3)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "be38d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cv_results_ = cross_validate(classifier, Xtrain, Ytrain, cv=cv,\n",
    "                                                     scoring=['f1'],\n",
    "                                                     return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9bb9e25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None,\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
       "                grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=132, n_jobs=-1, num_parallel_tree=None,\n",
       "                objective='binary:logistic', predictor=None, random_state=0, ...)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_0 = cv_results_['estimator'][0]\n",
    "classifier_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "36ee0bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>estimator</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.224</td>\n",
       "      <td>0.012</td>\n",
       "      <td>XGBRFClassifier(base_score=None, booster=None,...</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.229</td>\n",
       "      <td>0.012</td>\n",
       "      <td>XGBRFClassifier(base_score=None, booster=None,...</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.232</td>\n",
       "      <td>0.012</td>\n",
       "      <td>XGBRFClassifier(base_score=None, booster=None,...</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.253</td>\n",
       "      <td>0.015</td>\n",
       "      <td>XGBRFClassifier(base_score=None, booster=None,...</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.238</td>\n",
       "      <td>0.012</td>\n",
       "      <td>XGBRFClassifier(base_score=None, booster=None,...</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time                                          estimator  \\\n",
       "0     1.224       0.012  XGBRFClassifier(base_score=None, booster=None,...   \n",
       "1     1.229       0.012  XGBRFClassifier(base_score=None, booster=None,...   \n",
       "2     1.232       0.012  XGBRFClassifier(base_score=None, booster=None,...   \n",
       "3     1.253       0.015  XGBRFClassifier(base_score=None, booster=None,...   \n",
       "4     1.238       0.012  XGBRFClassifier(base_score=None, booster=None,...   \n",
       "\n",
       "   test_f1  \n",
       "0    0.789  \n",
       "1    0.789  \n",
       "2    0.796  \n",
       "3    0.795  \n",
       "4    0.791  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = round(pd.DataFrame(cv_results_),3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b19bfe1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cross_validate() got an unexpected keyword argument 'strategy_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46868\\3317764412.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m cv_results_ = cross_validate(classifier_0, Xtrain, Ytrain, cv=cv,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                                      scoring=['roc_auc',\n\u001b[0;32m      4\u001b[0m                                                               \u001b[1;34m'average_precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                               'balanced_accuracy'],\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_validate() got an unexpected keyword argument 'strategy_name'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cv_results_ = cross_validate(classifier_0, Xtrain, Ytrain, cv=cv,\n",
    "                                                     scoring=['roc_auc',\n",
    "                                                              'average_precision',\n",
    "                                                              'balanced_accuracy'],\n",
    "                                                     strategy_name=\"Cost-sensitive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
